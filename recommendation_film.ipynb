{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyON0LoydvQ8sHv+12OKg5La",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alinaderi1378/Recomendation_film/blob/main/recommendation_film.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Be-2pi70sohF"
      },
      "outputs": [],
      "source": [
        "!pip install pandas scikit-learn nltk hazm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ø¨Ø±Ø§ÛŒ Ù…Ø­ÛŒØ· Ø¯Ø³Ú©ØªØ§Ù¾ ÛŒØ§ Google Colab\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "import os\n",
        "\n",
        "!pip install hazm\n",
        "try:\n",
        "    from hazm import stopwords_list, Normalizer\n",
        "except ImportError:\n",
        "    print(\"Ù†ØµØ¨ hazm...\")\n",
        "    os.system(\"pip install hazm\")\n",
        "    from hazm import stopwords_list, Normalizer\n",
        "# Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ù†Ø§Ø¨Ø¹ Ù„Ø§Ø²Ù…\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§\n",
        "df = pd.read_csv('movies_farsi.csv', encoding='utf-8')\n",
        "df['overview'] = df['overview'].fillna('')"
      ],
      "metadata": {
        "id": "u-YBYLgow7Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ\n",
        "normalizer = Normalizer()\n",
        "stop_words = set(stopwords_list())\n",
        "\n",
        "def preprocess(text):\n",
        "    text = normalizer.normalize(text)\n",
        "    tokens = text.split()\n",
        "    tokens = [t for t in tokens if t not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['overview_clean'] = df['overview'].apply(preprocess)\n",
        "\n",
        "# Ø¨Ø±Ø¯Ø§Ø±Ø³Ø§Ø²ÛŒ Ø¨Ø§ TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(df['overview_clean'])\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# ØªØ§Ø¨Ø¹ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ ÙÛŒÙ„Ù…\n",
        "def get_recommendations(movie_title, top_n=3):\n",
        "    if movie_title not in df['title'].values:\n",
        "        return [f\"ÙÛŒÙ„Ù… Â«{movie_title}Â» ÛŒØ§ÙØª Ù†Ø´Ø¯.\"]\n",
        "    idx = df[df['title'] == movie_title].index[0]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
        "    return [f\"{df.iloc[i]['title']} (Ø´Ø¨Ø§Ù‡Øª: {score:.2f})\" for i, score in sim_scores]\n",
        "\n",
        "\n",
        "print(\"ğŸ¬ Ù„ÛŒØ³Øª ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯:\")\n",
        "for idx, title in enumerate(df['title']):\n",
        "    print(f\"{idx + 1}. {title}\")\n",
        "\n",
        "movie_index = int(input(\"\\nØ´Ù…Ø§Ø±Ù‡ ÙÛŒÙ„Ù… Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯: \")) - 1\n",
        "\n",
        "if 0 <= movie_index < len(df):\n",
        "    selected_title = df.iloc[movie_index]['title']\n",
        "    print(f\"\\nâœ… ÙÛŒÙ„Ù… Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡: Â«{selected_title}Â»\")\n",
        "    print(\"ğŸ¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ ÙÛŒÙ„Ù…â€ŒÙ‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡:\\n\")\n",
        "    recommendations = get_recommendations(selected_title)\n",
        "    for i, rec in enumerate(recommendations, 1):\n",
        "        print(f\"{i}. {rec}\")\n",
        "else:\n",
        "    print(\"Ø´Ù…Ø§Ø±Ù‡ ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IMgNE_F9tC75"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}